# PaperReadingList


## Pretraining

### BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding

- **作者 / 机构**：Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova / Google  
- **年份 / 会议**：2019 / NAACL  
- **论文链接**：[PDF](https://arxiv.org/abs/1810.04805)  
 
 ### Contextual Word Representations: A Contextual Introduction

- **作者 / 机构**：Noah A. Smith  
- **年份 / 会议**：2019 / arXiv  
- **论文链接**：[PDF](https://arxiv.org/abs/1902.06006)  